# -*- coding: utf-8 -*-
"""ade_examples_hackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jUqMigF63gK3ZnctiWTJk5MqIkOfMQzu

# LandingAI ADE Python Library Examples

This notebook demonstrates various usage patterns for the ADE (Automated Document Extraction) Python library.
"""

# LandingAI ADE Python SDK
!pip install landingai-ade

# For .env authentication file support
!pip install pydantic_settings
# install pillow for image processing
!pip install pillow
# install pymupdf for pdf processing
!pip install pymupdf
# install matplotlib for visualization
!pip install matplotlib

"""## 1. Authentication"""

# Method 1: Environment variable
def get_api_key() -> str:
    import os

    key = os.environ.get("VISION_AGENT_API_KEY")
    if not key:
        raise ValueError(
            "API key not found. Please set the VISION_AGENT_API_KEY environment variable."
        )
    return key


# Method 2: From .env file with Pydantic settings
def get_api_key_env() -> str:
    from pydantic_settings import BaseSettings

    class Settings(BaseSettings):
        vision_agent_api_key: str

        class Config:
            env_file = ".env"

    settings = Settings()
    return settings.vision_agent_api_key


# Initialize the client
from landingai_ade import LandingAIADE

from google.colab import userdata

client = LandingAIADE(apikey=userdata.get('VISION_AGENT_API_KEY'))

print("Authenticated client initialized")

"""## 2. Parse"""

from pathlib import Path
import json

from landingai_ade.types import ParseResponse


def parse_document(
    client: LandingAIADE, document_path: str, model: str = "dpt-2-latest"
) -> ParseResponse:
    """Parse a document and return both global and chunk-level markdown."""
    response = client.parse(document=Path(document_path), model=model)
    return response


# Example usage
parse_filename = "sample-invoice.pdf"
parse_result = parse_document(client, parse_filename)

with open("sample-invoice.md", "w") as fd:
    fd.write(parse_result.markdown)

with open("sample-invoice.json", "w", encoding="utf-8") as f:
        f.write(json.dumps(parse_result.model_dump(), indent=2, default=str))

print("Global markdown:", parse_result.markdown[:1000] + "...")
print(f"Number of chunks: {len(parse_result.chunks)}")

"""## 3. Extraction"""

from pydantic import BaseModel, Field

from landingai_ade.types import ExtractResponse
from landingai_ade.lib import pydantic_to_json_schema


# Define extraction schemas
class InvoiceItem(BaseModel):
    quantity: float = Field(
        description="Item quantity, typically hours",
        title="Quantity"
    )
    service: str = Field(
        description="The service performed.",
        title="Service"
    )
    rate: str = Field(
        description="The rate per unit of quantity.",
        title="Rate"
    )
    total: str = Field(
        description="The total cost for the item.",
        title="Total"
    )

class Invoice(BaseModel):
    invoice_number: str = Field(
        description="The invoice number.",
        title="Invoice Number"
    )
    invoice_date: str = Field(
        description="The invoice date.",
        title="Invoice Date"
    )
    total_due: float = Field(
        description = "The total amount due.",
        title = "Total Due"
    )
    itemized_invoice: list[InvoiceItem]


def extract_schema(
    client: LandingAIADE, markdown_path: str, schema_class: BaseModel
) -> ExtractResponse:
    """Extract structured data from markdown using a Pydantic schema."""
    # Convert Pydantic model to JSON schema
    json_schema = pydantic_to_json_schema(schema_class)
    # Perform extraction
    response = client.extract(schema=json_schema, markdown=Path(markdown_path))
    return response, json_schema


# Example usage - Extract invoice information
extraction_result, schema = extract_schema(client, "sample-invoice.md", Invoice)
extraction = extraction_result.extraction
metadata = extraction_result.extraction_metadata

with open("sample-invoice-schema.json", "w", encoding="utf-8") as fd:
    fd.write(json.dumps(schema, indent=2, default=str))

with open("sample-invoice-structured.json", "w", encoding="utf-8") as fd:
    fd.write(json.dumps(extraction, indent=2, default=str))

print(extraction)
print(metadata)

"""## 4. Visualization"""

from typing import Dict
from datetime import datetime

import pymupdf
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw

from landingai_ade.types.parse_response import Grounding


def create_annotated_image(
    img: Image.Image, groundings: Dict[str, Grounding], page_num: int
) -> Image.Image:
    """Create an annotated image with grounding boxes and labels."""
    annotated_img = img.copy()
    draw = ImageDraw.Draw(annotated_img)
    colors = [
        (255, 0, 0),
        (0, 255, 0),
        (0, 0, 255),
        (255, 255, 0),
        (255, 0, 255),
        (0, 255, 255),
    ]

    img_width, img_height = img.size
    color_idx = 0

    for gid, grounding in groundings.items():
        # Check if grounding belongs to this page (for PDFs)
        if grounding.page != page_num:
            continue

        box = grounding.box

        # Extract coordinates from box
        left, top, right, bottom = box.left, box.top, box.right, box.bottom

        # Convert to pixel coordinates
        x1 = int(left * img_width)
        y1 = int(top * img_height)
        x2 = int(right * img_width)
        y2 = int(bottom * img_height)

        # Draw bounding box
        color = colors[color_idx % len(colors)]
        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        # Draw label background and text
        label = f"{grounding.type}:{gid}"
        label_y = max(0, y1 - 20)
        draw.rectangle([x1, label_y, x1 + len(label) * 8, y1], fill=color)
        draw.text((x1 + 2, label_y + 2), label, fill=(255, 255, 255))

        color_idx += 1

    return annotated_img


def save_image_with_timestamp(
    img: Image.Image, output_path: Path, base_name: str, suffix: str, timestamp: str
) -> Path:
    """Save image with timestamp and return the path."""
    filename = f"{base_name}_{suffix}_{timestamp}.png"
    image_path = output_path / filename
    img.save(image_path)
    return image_path


def display_image_in_jupyter(
    img: Image.Image, title: str = "Document with Grounding Boxes"
) -> None:
    """Display image in Jupyter notebook."""
    fig, ax = plt.subplots(1, 1, figsize=(15, 10))
    ax.imshow(img)
    ax.set_title(title)
    ax.axis("off")
    plt.tight_layout()
    plt.show()


def process_pdf_pages(
    pdf_path: str, response: ParseResponse, output_path: Path, timestamp: str
) -> None:
    """Process all pages of a PDF document."""
    pdf = pymupdf.open(pdf_path)
    total_pages = len(pdf)
    base_name = Path(pdf_path).stem

    for page_num in range(total_pages):
        page = pdf[page_num]
        pix = page.get_pixmap(matrix=pymupdf.Matrix(2, 2))  # 2x scaling
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        # Save original page
        original_path = save_image_with_timestamp(
            img, output_path, base_name, f"page_{page_num + 1}", timestamp
        )
        print(f"Saved page {page_num + 1} to: {original_path}")

        # Create and save annotated version
        if response.grounding:
            annotated_img = create_annotated_image(img, response.grounding, page_num)
            annotated_path = save_image_with_timestamp(
                annotated_img,
                output_path,
                base_name,
                f"page_{page_num + 1}_annotated",
                timestamp,
            )
            print(f"Saved annotated page {page_num + 1} to: {annotated_path}")

            # Only display first page in Jupyter
            if page_num == 0:
                display_image_in_jupyter(annotated_img)

    pdf.close()


def process_image_file(
    image_path: str, response: ParseResponse, output_path: Path, timestamp: str
) -> None:
    """Process a single image file."""
    img = Image.open(image_path)
    if img.mode != "RGB":
        img = img.convert("RGB")

    base_name = Path(image_path).stem

    # Save original image
    original_path = save_image_with_timestamp(
        img, output_path, base_name, "", timestamp
    )
    print(f"Saved image to: {original_path}")

    # Create and save annotated version
    if response.grounding:
        annotated_img = create_annotated_image(img, response.grounding)
        annotated_path = save_image_with_timestamp(
            img, output_path, base_name, "annotated", timestamp
        )
        print(f"Saved annotated image to: {annotated_path}")

        # Display in Jupyter
        display_image_in_jupyter(annotated_img)


def visualize_document(
    response: ParseResponse, parse_filename: str, output_dir: str = "./ade_results"
) -> None:
    """Visualize document groundings for debugging and save all pages."""
    if response.grounding is None or len(response.grounding) == 0:
        print("No groundings found in response")
        return

    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Handle both PDF and image files
    if parse_filename.lower().endswith(".pdf"):
        process_pdf_pages(parse_filename, response, output_path, timestamp)
    elif parse_filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp", ".tiff")):
        process_image_file(parse_filename, response, output_path, timestamp)


# Example usage
visualize_document(parse_result, "sample-invoice.pdf")

